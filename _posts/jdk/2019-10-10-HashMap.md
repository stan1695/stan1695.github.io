---
title: jdk1.8 HashMap实现原理
categories:
 - jdk
tags: 
 - Collection
 - HashMap 
---

# HashMap代码详解-jdk1.8

## 概述
* HashMap是我们日常开发中最常用的一个集合类，  
* hashmap允许key,value都为null,key为null的哈希值为0，  
* 如果有相同的key进行插入，将会先插入的key的value替换成新的value,  
* hashmap并不能保证键值对的顺序，如果需要考虑顺序，请了解LinkedHashMap（继承了hashmap）
* hashmap是非线性安全类，如果需要考虑线性安全，请了解ConcurrentHashMap(没有继承hashmap，但是与hashmap是同一个父类AbstractMap)


## 原理
HashMap数据结果图如下：
![image](https://github.com/stan1695/stan1695.github.io/blob/master/_posts/image/hashmap-jiegou.jpg?raw=true)

如上图，其数据结果是由数组和链表(或树结果组成)，在进行增删改查等操作时，首先要定位到元素所在槽的位置，之后再从链表定位到该元素。
比如：  
    1、定位元素35所在位置，index = 35 % 16 = 3;  
    2、在3号槽所指向的链表中继续查找，发现35在链表中。

## 1、HashMap构成方法

 * HashMap的构造方法不多，只有4个，构造方法做的事情不多，只是初始化一些重要的变量，而底层的数据结构是延迟到插入键值对数据时在进行初始化。HashMap的构造方法如下：
    ```
    //构造方法1：
    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
    }

    //构造方法2：
    public HashMap(int initialCapacity) {
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
    }

    //构造方法3：
    public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +
                                                initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                                                loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }

    //构造方法4：
    public HashMap(Map<? extends K, ? extends V> m) {
        this.loadFactor = DEFAULT_LOAD_FACTOR;
        putMapEntries(m, false);
    } 
    ```

    上面4个构造方法中，大家常用的是构造方法1，方法1很简单，只是将loadFactor(负载因子)初始化为默认值（0.75f）；方法2，则是传入了HashMap的初始化长度，负载因子还是默认的0.75f,紧接着就调用了构造方法3，方法3做了2个值的初始化，第一加载因子，第二扩容阀值，如果输入的hashmap长度大于默认的最大值（MAXIMUM_CAPACITY），将HashMap长度调整为默认的最大值。方法4则是将另外一个map拷贝映射到自己存储结构中来，这个方法比较少用。

    方法3，输入了HashMap的初始长度和负载因子，但是扩容阀值threshold确不是上面介绍的initialCapacity*loadFactor而是调用了tableSizeFor方法。
    ```
    static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
    ```
    这里对n做了5次与或运算，结果就是取比cap大的最小的2次幂。比如:  

    十进制|二进制|运算|运算后结果（二进制）
    --|:--|:--|:--
    cap= 34|00010010|
    n=33||cap-1|00010001
    n||n >>> 1|00001000
    n||n \|= n >>> 1|00011001
    n||n \|= n >>> 2|00011111
    n||n \|= n >>> 4|00011111
    n||n \|= n >>> 8|00011111
    n|63|n \|= n >>> 16|00011111  

    所以tableSizeFor最终返回的是n+1=64,  
    00001000  
    00010001  
    这两个数求与或：00011001

## 2、重要的变量与常量

  变量名称|用途|说明
  --|:--|:--
  initialCapacity|HashMap 初始容量|默认最大值MAXIMUM_CAPACITY
  loadFactor|负载因子|负载因子默认值DEFAULT_LOAD_FACTOR
  threshold|扩容阀值|当HashMap所容纳的值大于该值是需要进行扩容，该值一般等于initialCapacity*loadFactor
  MAXIMUM_CAPACITY|HashMap 容量最大值（1 << 30）2的30次方|当HashMap的容量大于这个值时，将不再扩容,为什么是2^30而不是2^31-1呢，因为hash槽的长度是2次幂，而2的31次幂在32位有符号二进制中表示的是一个负数。
  DEFAULT_LOAD_FACTOR|默认负载因子，值为0.75f
  TREEIFY_THRESHOLD|链表树化阀值，值为8|链表长度大于或等于树化阈值，则进行树化操作
  MIN_TREEIFY_CAPACITY|树化扩容阀值，值为64|当HashMap数组容量小于 MIN_TREEIFY_CAPACITY，优先进行扩容而不是树化

 * 在数据结果中听的比较多的一句话，【用时间换空间，用空间换时间】，我们来看看HashMap中的时间和空间，负载因子就是HashMap中一个调节时间和空间的平衡。  

 * 调大负载因子（负载因子可以大于1）：HashMap槽中存入的键值对就多，空间利用率高，但是碰撞率也高，这意味着链表长度变长，效率也随之降低，这种情况是拿时间换空间。  

 * 调小负载因子：HashMap 所能容纳的键值对数量变少。扩容时，重新将键值对存储新的槽数组里，键与键之间产生的碰撞会下降，链表长度变短。此时，HashMap 的增删改查等操作的效率将会变高，这里是典型的拿空间换时间。

 * 例如：HashMap的长度为16，负载因子为0.75f是，在加到第13个键值对时，就会扩容到32。如果负载因子是1，则是加到第17个键值对的时候才会扩容到32。说明同样是16长度的hashMap负载因子0.75f的hashMap只存入了12个数，而负载因子是1的hashmap存入了16个数。在同样长度的hashmap中16个数也更容易发送碰撞，发生了碰撞之后数据就会存入链表中，这样链表的长度也更长，在惊喜增删改查是效率也更低。
  
## 查找
* 查找的步骤其实就是上面原理的那节讲的，先找到键值对所在槽的位置，然后再对链表和红黑树进行查找。查看getNode的源码
```
public V get(Object key) {
Node<K,V> e;
return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node<K,V> getNode(int hash, Object key) {
Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
if ((tab = table) != null && (n = tab.length) > 0 &&
    (first = tab[(n - 1) & hash]) != null) {
        //定位key的hash值求余所得hash槽的位置，hash值相等，key也相等，则返回first节点，
    if (first.hash == hash && // always check first node
        ((k = first.key) == key || (key != null && key.equals(k))))
        return first;
    if ((e = first.next) != null) {
        //说明first是一个链表或红黑数
        if (first instanceof TreeNode)
        //红黑树查找
            return ((TreeNode<K,V>)first).getTreeNode(hash, key);
        do {
            //链表查找
            if (e.hash == hash &&
                ((k = e.key) == key || (key != null && key.equals(k))))
                return e;
        } while ((e = e.next) != null);
    }
}
return null;
}

static final int hash(Object key) {
int h;
return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```
* 上述代码，解释查找节点的核心代码，里面我加了注释，相信应该能看懂。  
  这里讲一个表达式【(n - 1) & hash】，n是hash槽的长度，总是2的幂，这里n-1和hash值求与运算等价于hash对n求余。  
  比如：hash=67,n=64 求余为3，与运算：n-1 = 63  
  63：0001 1111  
  67：0010 0011  
  & ：0000 0011 = 3

* 在调getNode方法之前会调一个hash方法，获取hashCode之后重新通过位运算获取hash值，为什么不直接用hashcode而是通过hashcode异或运算hashcode右移16位来做hash值呢？我们看上面通过hash求余来定位hash槽的表达式【(n - 1) & hash】在n比较小的情况下，只有n的地位算参与计算是有效的，而高位数的运算都是0，运算都是0，是无效的，为了让高位数也参与进行运算，是的hash的运算更复杂，进行影响hash的分不性。

## 遍历  
```
HashIterator() {
    expectedModCount = modCount;
    Node<K,V>[] t = table;
    current = next = null;
    index = 0;
    if (t != null && size > 0) { // advance to first entry
    //遍历器初始化，赋值第一个不为空node给next节点
        do {} while (index < t.length && (next = t[index++]) == null);
    }
}

final Node<K,V> nextNode() {
        Node<K,V>[] t;
        Node<K,V> e = next;
        if (modCount != expectedModCount)
            throw new ConcurrentModificationException();
        if (e == null)
            throw new NoSuchElementException();
        if ((next = (current = e).next) == null && (t = table) != null) {
            do {} while (index < t.length && (next = t[index++]) == null);
        }
        return e;
    }


```
例如：  
```
HashMap map = new HashMap();
	map.put(1,1);
    map.put(7,7);
    map.put(23,23);
    map.put(22,22);
    map.put(6,6);
    Iterator it= map.entrySet().iterator();
    for(;;){
        if(it.hasNext()){
            System.out.println("args = [" + it.next().toString() + "]");
        }else{
            break;
        }
    }
```
上述输入的结果是：  
args = [1=1]  
args = [22=22]  
args = [6=6]  
args = [7=7]  
args = [23=23]  

说明 HashMap插入顺序和遍历顺序不相同，因为它是通过Hash槽的下角标依次往下遍历的。上述map中6和22是在同一个Hash槽，而7和23又在另一个Hash槽，假设Hash槽是table[],table[2]=Node<1,1>,table[7]=Node<22,22>,table[7].next=Node<6,6>,table[8]=Node<7,7>,table[8].next=Node<23,23>。


## 插入  
通过前面的hashmap数据结构和遍历的介绍，对于插入的逻辑也基本清晰了，首先肯定是先定位要插入的键值对属于哪个槽，定位到槽后，再判断槽是否为空。如果为空，则将键值对存入即可。如果不为空，则需将键值对接在链表最后一个位置，或者更新键值对。这是简化版的插入流程，其实源代码比这复杂一点。
```
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
        //第一添加数据，初始化一下hash槽的容量
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
        //进行hash碰撞，没有碰撞成功，说明是在一个新的hash槽中
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                //hash碰撞成功，并且key相同，则直接替换就节点的value
                e = p;
            else if (p instanceof TreeNode)
            //如果hash槽中的节点引用类型为 TreeNode 则调用红黑树的插入方法
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                //对链表进行遍历，并统计链表长度binCount
                for (int binCount = 0; ; ++binCount) {
                    //当前链表中的节点（p）的next为空，则将加在该节点后面
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        // 如果链表长度大于或等于树化阈值，则进行树化操作
                            treeifyBin(tab, hash);
                        break;
                    }
                    //当前链表中的节点（p）的next不为空，且key相等，终止循环
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        // 键值对数量超过阈值时，则进行扩容
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```
1、当hash槽数组table为空时，通过扩容的方法初始化table。  
2、查找要插入的键值对是否已经存在，存在的话根据条件判断是否用新值替换旧值。  
3、如果不存在，则将键值对链入链表中，并根据链表长度决定是否将链表转为红黑树。  
4、判断键值对数量是否大于阈值，大于的话则进行扩容操作。

## 扩容机制

平时我们定义数组的时候，一定是要明确定义数组的长度，而hashMap数据结构中的hash槽就是一个数组，但是我们在定义时可以不用什么长度，而且put值时却是可以无限put。很多时候我们无法知道该建多大的数组合适。建小了不够用，建大了用不完，造成浪费。那如何做到不限定长度，但又不浪费空间。这就要归功于hashmap中的扩容操作。  
在hashmap中，hash槽的长度都是2次幂（1，2，4，8，16，32...）,阀值的大小为槽数组长度与负载因子的乘积，当hashmap中键值对数量超过阀值时，将进行扩容，增加hash槽长度。  
hash槽的长度都是2次幂，说明每次扩容都是翻倍扩充的，阀值也是翻倍扩充。扩容之后，要重新计算键值对的位置，并把它们移动到合适的位置上去。以上就是 HashMap 的扩容大致过程，接下来我们来看看具体的实现：  
```
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        //table不为空，说明已经初始化过
        if (oldCap >= MAXIMUM_CAPACITY) {
            //当table长度超过最大值，不在扩容，
            //思考：为什么阀值要设置成2的31次方-1
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        //新容量=旧容量*2,
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                    oldCap >= DEFAULT_INITIAL_CAPACITY)
                    //如果就容量大于16，阀值也2倍扩大
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
    //初始化时，table为空 table长度=阀值
    //调用有长度的hashmap构造函数时,会进入这里
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
    //调用无长度的hashmap构造函数时,会进入这里
    //默认16，阀值16*0.75=12
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        //阀值扩充（位运算）之后,可能溢出
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                    (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    // 创建新的槽数组，槽数组的初始化也是在这里完成的
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 如果旧的槽数组不为空，则遍历槽数组，并将键值对映射到新的槽数组中
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    // 重新映射时，需要对红黑树进行拆分
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        // 遍历链表，并将链表节点按原顺序进行分组
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```
上述代码比较复杂，做的主要是以下几点  
1、计算新槽数组的容量 newCap 和新阈值 newThr  
2、根据计算出的 newCap 创建新的槽数组，槽数组 table 也是在这里进行初始化的。（这里只有一行代码Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];）  
3、将键值对节点重新映射到新的槽数组里。如果节点是 TreeNode 类型，则需要拆分红黑树。如果是普通节点，则节点按原顺序进行分组。  

* 第一点就是前面的if,else if ,else  
    
  条件|覆盖情况|备注
  --|:--|:--  
  oldCap > 0|槽数组 table 已经被初始化|  
  oldThr > 0|threshold > 0，且槽数组未被初始化|调用 HashMap(int) 和 HashMap(int, float) 构造方法时会产生这种情况，此种情况下 newCap = oldThr，newThr 在第二个条件分支中算出，其实这里构造方法里面是有一个初始化阀值的方法tableSizeFor  
  oldCap == 0 && oldThr == 0|槽数组未被初始化，且 threshold 为 0|调用 HashMap() 构造方法会产生这种情况。  

  边界值判断  

  条件|覆盖情况|备注
  --|:--|:--
  oldCap >= 2^30|槽数组容量大于或等于最大槽容量 2^30|这种情况下不再扩容
  newCap < 2^30 && oldCap > 16|新槽数组容量小于最大值，且旧槽数组容量大于 16|该种情况下新阈值 newThr = oldThr << 1，移位可能会导致溢出，溢出之后newThr=0
  newThr == 0|| newCap = oldCap << 1，newCap永远为2次幂，且最大为2^30,它这里是不会存在溢出的。

* 第三点，进行重新分组  
  1、扩容之后的hash求余运算，其实是增加了一个高位为1加入运算。  
  比如：容量是16时，求余运算是：hash&(16-1)=hash&1111  
  容量是32时的求余运算是：hash&(32-1)=hash&1 1111  
  
  2、其实就看hash与新加的高位运算的结果，如果与高位运算结果是0，说明还在原来的hash槽，如果结果是1，则是往下移了扩容量个hash槽。这也就是为什么代码里面要用e.hash & oldCap来运算了。loHead表示链表中求余（e.hash & oldCap）为0的第一个节点，loTail表示链表中求余（e.hash & oldCap）为0的最后一个节点，hiHead表示链表中求余（e.hash & oldCap）为非0的第一个节点，hiTail表示链表中求余（e.hash & oldCap）为非0的最后一个节点。  

  3、所以扩容之后的求余，要么在原来的位置，要么就是往下移动了扩容个位置，如果原来是单个节点的hash槽，扩容之后还是单个节点，原来是链表的hash槽，扩容之后可能拆分出两个hash槽。  

  4、红黑树节点仍然保留了 next 引用，故仍可以按链表方式遍历红黑树。

  5、重新映射红黑树的逻辑和重新映射链表的逻辑基本一致。不同的地方在于，重新映射后，会将红黑树拆分成两条由 TreeNode 组成的链表。如果链表长度小于 UNTREEIFY_THRESHOLD（6），则将链表转换成普通链表。否则根据条件重新将 TreeNode 链表树化。

## 删除
HashMap 的删除操作并不复杂，仅需三个步骤即可完成。第一步是定位槽位置，第二步遍历链表并找到键值相等的节点，第三步删除节点。
```
final Node<K,V> removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable) {
        Node<K,V>[] tab; Node<K,V> p; int n, index;
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (p = tab[index = (n - 1) & hash]) != null) {
            Node<K,V> node = null, e; K k; V v;
            // 1. 定位槽位置
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                // 如果键的值与链表第一个节点相等，则将 node 指向该节点
                node = p;
            else if ((e = p.next) != null) {
                if (p instanceof TreeNode)
                // 如果是 TreeNode 类型，调用红黑树的查找逻辑定位待删除节点
                    node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
                else {
                    // 2. 遍历链表，找到待删除节点
                    do {
                        if (e.hash == hash &&
                            ((k = e.key) == key ||
                             (key != null && key.equals(k)))) {
                            node = e;
                            break;
                        }
                        p = e;
                    } while ((e = e.next) != null);
                }
            }
            // 3. 删除节点，并修复链表或红黑树
            if (node != null && (!matchValue || (v = node.value) == value ||
                                 (value != null && value.equals(v)))) {
                if (node instanceof TreeNode)
                    ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
                else if (node == p)
                    tab[index] = node.next;
                else
                    p.next = node.next;
                ++modCount;
                --size;
                afterNodeRemoval(node);
                return node;
            }
        }
        return null;
    }
```
可以留意到，删除节点并不会改变hashmap的容量和阀值。

## 其他一些细节
1、可以看到hashmap中很多属性都加了transient 修饰符，transient 表示易变的意思，在 Java 中，被该关键字修饰的变量不会被默认的序列化机制序列化。HashMap的序列化是通过实现readObject/writeObject两个方法自定义了序列化的内容。他们序列化的是键值对，反序列化的时候在重建hashmap。序列化键值对而不序列化table，其实有2个考虑：1、table中有很多一部分是空的，没有存放键值对，序列化table的话就会浪费一部分资源空间。2、键值对在不同的jvm下所处的槽可能会不一样，所以重新建立hashmap是最靠谱的。  
。。。有待补充

## 总结
本文主要是对hashmap类进行代码解读，包括了hashmap的插入、遍历、查找、删除、扩容等。其中红黑树部分的介绍比较少，一笔带过，没有深入讲解。后续有空再进行红黑树的学习。但是上述大篇幅的内部基本把hashmap的设计原理能够讲述清楚。总的来说，插入操作在hashMap中是最为复杂的。hashmap中存在大量的位运算，平时写代码很少运用这些，所以看起来可能会卡顿一下。所以本文对这些表达式讲述的比较详细。

## 写在最后
这篇文章花了大概一周的业余时间完成。有些地方可能讲述的不太清楚，后期继续学习补充。看原码，在没有一点基本了解的情况下就下手，看起来会很费劲。看源码之前，还是需要提前了解一下基本的原理和知识点的轮廓。看源码时可以适当的写一下单元测试，打断点进行阅读代码，这样更容易理解每一行代码。如果本文有错误或者理解不到位，希望大家指出来，及时修改。最后希望这篇文章对大家有点帮助。  

<img  src="https://github.com/huanglu050816/resource-wk/blob/master/1572330107.jpg?raw=true" align='right'/>