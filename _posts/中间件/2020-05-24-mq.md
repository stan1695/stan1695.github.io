---
title: mq 
categories:
 - 中间件
tags: 
 - mq
 - kafka
 - rabbitmq
---

# mq

## rabbitMq

## kafka

### kafka的消息是存储在文件系统之上的

### 存储方式

#### topic

##### partition,
一个topic可能配置多个partition，默认是1个，
每个partition与topic组成一个目录，比如topic-0,topic-1...

###### segment file
每一个partition文件目录下有多对index/log文件
每一对index/log文件组成了segment file

####### index file 索引文件(.index)

######## index文件中的消息并不是有规则的，而是采用了稀疏索引存储，
每隔一定间距创建一条索引，也就是说并不是每条消息都能在index文件中找到索引的。

######### 减小索引文件的大小

######### 可以把有限的index映射到内存。

####### data file 数据文件(.log)

######## 每一条message

######### offset

########## 表示 message 在当前 Partition 中的偏移量，是一个逻辑上的值，唯一确定了 Partition 中的一条 message，可以简单的认为是一个 id；

######### MessageSize

########## 表示 message 内容 data 的大小；

######### data

########## message 的具体内容

####### segment file kafka文件存储的最小单位

####### segment file 命名规则

######## partition全局目录的第一个segment从0开始，
后续每个 Segment 文件名为上一个 Segment 文件最后一条消息的 offset 值

####### 因为segment file上有最后一条数据的offset字段，因此当需要查找指定offset数据时，可以通过二分查找。

####### 由于消息在 Partition 的 Segment 数据文件中是顺序读写的，且消息消费后不会删除（删除策略是针对过期的 Segment 文件），这种顺序磁盘 IO 存储设计师 Kafka 高性能很重要的原因。 

### 生产者

#### 1、创建一个ProducerRecord

##### topic（主题）

##### partition（分区）

###### 可选

##### key（键值）

###### 可选

##### value（值）

#### 2、将第一步生产的消息信息（key/value）系列化并发送到partitioner（分配器）

##### partitioner就是由topic和partition共同构成的

#### 3、这条记录添加到相同主题和分区的批量消息中

##### 另一个线程负责发送这些批量消息到对应的Kafka broker

#### 4、当broker接收到消息后，如果成功写入则返回一个包含消息的主题、分区及位移的RecordMetadata对象，否则返回异常。

#### 5、生产者接收到结果后，对于异常可能会进行重试

### 消费者

#### 消费组

##### 当多个消费者形成一个消费组来消费主题时，每个消费者会收到不同分区的消息

##### 可以通过增加消费组的消费者来进行水平扩展提升消费能力。
这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。

##### 消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。

##### Kafka一个很重要的特性就是，只需写入一次消息，可以支持任意多的应用读取这个消息。

###### 为了使得每个应用都能读到全量消息，应用需要有不同的消费组

###### 如果应用需要读取全量消息，那么请为该应用设置一个消费组；
如果该应用消费能力不足，那么可以考虑在这个消费组里增加消费者。

#### 重平衡（rebalance）

##### 当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；
另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区

##### 重平衡是 Kafka 一个很重要的性质，这个性质保证了高可用和水平扩展

##### 不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。

##### 将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能。

##### 消费者通过定期发送心跳（hearbeat）到一个作为组协调者（group coordinator）的 broker 来保持在消费组内存活。
当消费者拉取消息或者提交时，便会发送心跳。
如果消费者超过一定时间没有发送心跳，那么它的会话（session）就会过期，组协调者会认为该消费者已经宕机，然后触发重平衡。
可以看到，从消费者宕机到会话过期是有一定时间的，这段时间内该消费者的分区都不能进行消息消费；
通常情况下，我们可以进行优雅关闭，这样消费者会发送离开的消息到组协调者，
这样组协调者可以立即进行重平衡而不需要等待会话过期。

#### 活锁（livelock） 

##### 是指应用没有故障但是由于某些原因不能进一步消费。

###### 高版本的 Kafka 支持配置一个消费者多长时间不拉取消息但仍然保持存活

###### 发送心跳与拉取消息进行分离，这样使得发送心跳的频率不受拉取的频率影响。

#### 问题

##### Kafka 中一个 topic 中的消息是被打散分配在多个 Partition(分区) 中存储的， 
Consumer Group 在消费时需要从不同的 Partition 获取消息，那最终如何重建出 Topic 中消息的顺序呢？

###### 没有办法。Kafka 只会保证在 Partition 内消息是有序的，而不管全局的情况。

##### Partition 中的消息可以被（不同的 Consumer Group）多次消费，那 Partition中被消费的消息是何时删除的？
 Partition 又是如何知道一个 Consumer Group 当前消费的位置呢？

###### 无论消息是否被消费，除非消息到期 Partition 从不删除消息。
例如设置保留时间为 2 天，则消息发布 2 天内任何 Group 都可以消费，2 天后，消息自动被删除。

###### 会为每个 Consumer Group 保存一个偏移量，记录 Group 消费到的位置。

##### push/pull

###### 由 Producer 向 broker push 消息
并由 Consumer 从 broker pull 消息

####### push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。
push 模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，
典型的表现就是拒绝服务以及网络拥塞。

####### pull 模式则可以根据 Consumer 的消费能力以适当的速率消费消息。

####### 对于 Kafka 而言，pull 模式更合适。
pull 模式可简化 broker 的设计，Consumer 可自主控制消费消息的速率，
同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费，
同时还能选择不同的提交方式从而实现不同的传输语义。

##### 可靠性保证

###### 对于一个分区来说，它的消息是有序的。如果一个生产者向一个分区先写入消息A，然后写入消息B，那么消费者会先读取消息A再读取消息B。

###### 当消息写入所有in-sync状态的副本后，消息才会认为已提交（committed）。
这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。
生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有in-sync状态副本写入才返回。

###### 一旦消息已提交，那么只要有一个副本存活，数据不会丢失。

###### 消费者只能读取到已提交的消息。
